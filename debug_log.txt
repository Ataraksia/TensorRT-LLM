Using post-processing delay pattern implementation ONLY
_fill_output called, result type: <class 'torch.Tensor'>
Result is tensor directly
output_ids_to_process type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 2048])
output_ids_list length: 1
First sequence length: 2048
First 20 tokens: [128000, 128000, 128006, 9125, 128007, 271, 32215, 7855, 2768, 7754, 13, 128018, 15097, 374, 12715, 505, 264, 11594, 3130, 815]
Found audio_out_bos positions: [72]
Context around audio_out_bos (pos 72): [128009, 128006, 78191, 128007, 271, 128013, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 2980, 2980, 2980, 2980, 996, 996, 2980, 2980, 1115, 996, 2980, 2980, 2980, 2980, 2980, 2980, 2980, 795, 2980, 2980, 2799, 2980, 2980, 1115, 461, 996, 1631, 1485, 2985, 996, 2799, 2980, 963, 5867, 2799, 2985, 769, 996, 996, 5949, 1271]
Audio generation stopped at position 81 with non-audio token: 2980
Collected 8 audio tokens
Raw audio tokens (first 50): [1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024]
Original frames shape: torch.Size([1, 8])
Post-vLLM-processing frames shape: torch.Size([1, 8])
Processed audio tokens (first 50): [1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024]
